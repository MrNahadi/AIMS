# SHAP Explainer Notebook Fix Summary

## Issue Identified

The SHAP explainer notebook (04_Model_Explainability_Export.ipynb) was failing during execution with the following error:

```
AssertionError: The shape of the shap_values matrix does not match the shape of the provided data matrix.
```

## Root Cause

The issue was caused by a mismatch between the SHAP values format returned by `TreeExplainer.shap_values()` and the format expected by `shap.summary_plot()`:

1. **Actual Format**: SHAP values were returned as a 3D numpy array with shape `(num_samples, num_features, num_classes)` = `(samples, 18, 8)`

2. **Expected Format**: The SHAP plotting functions expected either:
   - A list of 2D arrays: `[class_0_array, class_1_array, ..., class_7_array]`
   - Each array with shape `(num_samples, num_features)`

## Fixes Applied

### 1. SHAP Values Computation Cell
**Location**: Cell computing `shap_values = explainer.shap_values(X_test_scaled)`

**Fix**: Added conversion logic to transform 3D array to list format:

```python
shap_values_raw = explainer.shap_values(X_test_scaled)

# Convert SHAP values to list format for compatibility with SHAP plots
if isinstance(shap_values_raw, np.ndarray) and len(shap_values_raw.shape) == 3:
    # Shape: (samples, features, classes) -> list of (samples, features)
    shap_values = [shap_values_raw[:, :, i] for i in range(shap_values_raw.shape[2])]
elif isinstance(shap_values_raw, list):
    shap_values = shap_values_raw
else:
    shap_values = shap_values_raw
```

### 2. Beeswarm Plot Cell
**Location**: Cell generating SHAP summary plots (beeswarm)

**Fix**: Changed data source from `X_test_scaled_df` to `X_test` for better interpretability:

```python
shap.summary_plot(
    shap_values[class_idx],
    X_test,  # Use original unscaled data for better interpretability
    plot_type="dot",
    show=False,
    max_display=18
)
```

**Rationale**: Using unscaled data makes the feature values more interpretable in the visualization (e.g., actual RPM values instead of standardized z-scores).

### 3. Bar Plot Cell
**Location**: Cell generating SHAP bar plots (mean absolute values)

**Fix**: Same as beeswarm plot - changed to use `X_test` instead of `X_test_scaled_df`.

### 4. Verification Cell
**Location**: Cell verifying the saved SHAP explainer

**Fix**: Updated comparison logic to handle both 3D array and list formats:

```python
# Convert to same format for comparison
if isinstance(original_shap_raw, np.ndarray) and len(original_shap_raw.shape) == 3:
    original_shap_list = [original_shap_raw[:, :, i] for i in range(original_shap_raw.shape[2])]
else:
    original_shap_list = original_shap_raw

# Check if SHAP values match across all classes
shap_match = all([np.allclose(original_shap_list[i], loaded_shap_list[i]) 
                  for i in range(len(original_shap_list))])
```

## Verification

After applying the fixes, the notebook was successfully executed end-to-end:

✅ **All cells executed without errors**
✅ **SHAP explainer saved to**: `backend/artifacts/shap_explainer.pkl`
✅ **Visualizations generated**:
   - Beeswarm plots for all 8 fault classes
   - Bar plots showing mean absolute SHAP values
   - Partial Dependence Plots for top 5 features
   - Waterfall plots for individual predictions

## Impact on Backend API

The SHAP explainer artifact generated by the fixed notebook is fully compatible with the backend predictor service. The backend already handles the 3D array format correctly:

```python
# backend/services/predictor.py
shap_values = shap_explainer.shap_values(input_scaled)

# Extract SHAP values for predicted class
if isinstance(shap_values, list):
    shap_values_for_prediction = shap_values[int(prediction)][0, :]
else:
    # 3D array: [num_samples, num_features, num_classes]
    shap_values_for_prediction = shap_values[0, :, int(prediction)]
```

## Testing Results

The notebook now:
1. ✅ Loads model and data correctly
2. ✅ Computes SHAP values without errors
3. ✅ Generates all visualizations successfully
4. ✅ Saves SHAP explainer artifact
5. ✅ Verifies saved explainer works correctly

## Files Modified

- `notebooks/04_Model_Explainability_Export.ipynb` - Fixed SHAP value handling and visualization cells

## Files Generated

- `backend/artifacts/shap_explainer.pkl` - SHAP explainer artifact (regenerated with fixes)

## Conclusion

The SHAP explainer notebook is now fully functional and can be executed end-to-end without errors. All visualizations are generated correctly, and the SHAP explainer artifact is compatible with the backend API for real-time predictions with explanations.
